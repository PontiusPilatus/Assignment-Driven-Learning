{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Notes for Stanford CS143 Compilers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Week 01: Introduction & the Cool Programming Language\n",
    "\n",
    "**How to Run the Program**\n",
    "\n",
    "- Compiler (Offline)\n",
    "  - $Program \\rightarrow Compiler \\rightarrow Execute$\n",
    "  - $Execute + Data \\rightarrow Output$\n",
    "- Interpreters (Online)\n",
    "  - $Program + Data \\rightarrow Interpreter \\rightarrow Output$\n",
    "\n",
    "**Compiler Concept**\n",
    "\n",
    "- (Syntactic) **Lexical Analysis**\n",
    "  - Concept: Divide program text into words or tokens.\n",
    "  - Input: text\n",
    "  - Output: words or tokens\n",
    "  - Sample Input: `if x == y then z = 1; else z = 2;`\n",
    "  - Sample Output: `#IF #ID(x) #EQAUL #ID(y) #THEN ...`\n",
    "- (Syntactic) **Parsing**\n",
    "  - Concept: Diagramming Sentences.\n",
    "  - Input: Tokens\n",
    "  - Output: Abstruct Semantic Tree\n",
    "  - Sample Input: #INT(5) #PLUS #INT(3) #MULTIPLY #INT(5)\n",
    "  - Sample Output: `(#PLUS (#INT(5))  (#MULTIPLY (#INT(3))  (#INT(5))))`\n",
    "- (Types scope) **Semantic Analysis**\n",
    "  - Concept: Catch inconsistencies.\n",
    "  - Sample Input: `{ int Jack=3; { int Jack=4; cout << Jack; } }`\n",
    "  - Question: What is the value?\n",
    "- **Optimization**\n",
    "  - Concept: Run faster/Use less memory/Use low power/network.\n",
    "- (Translation) **Code Generation**\n",
    "  - Concept: Produce assembly code.\n",
    "\n",
    "**Related Questions**\n",
    "\n",
    "- Why are there so many programming languages?\n",
    "  - Application domains have distinct/conflicting needs.\n",
    "- Why are there new programming languages?\n",
    "  - Programming training is the dominant cost for a programming language.\n",
    "  - Wild-used languages are **slow to change**.\n",
    "  - Easy to start a new language: when **productivity** > **training cost**\n",
    "  - Languages adopted to fill a void. (**Void** means new techniques.)\n",
    "- What is a good programming languages?\n",
    "  - There is **no** universally accepted metric for language design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Week 02: Lexical Analysis & Finite Automata\n",
    "\n",
    "### 03 Lexical Analysis\n",
    "\n",
    "**Token Class (or Class)**\n",
    "\n",
    "Classify **program substrings** according to **role** (token class), **class** corresponding to **sets of strings**:\n",
    "\n",
    "- **Identifier** : string of letters or digits, starting with a letter\n",
    "- **Integer**: a non-empty string of digits\n",
    "- **Keyword**: else, if, begin, ...\n",
    "- **Whitespace**: a non-empty sequence of blanks, newlines, tabs\n",
    "\n",
    "**Goal of Lexical Analysis**\n",
    "\n",
    "- Definition\n",
    "\t- **lexeme**: A lexeme is a sequence of characters that matches the pattern for a token.\n",
    "\t- **token**: A token is a pair consisting of the token name and the value.\n",
    "- Concept\n",
    "\t- Parttition the input string into lexemes.\n",
    "\t- Identity the token of each lexeme.\n",
    "\t- Communicate tokens to the parser.\n",
    "- Input: Program Substrings\n",
    "- Output: Tokens\n",
    "- Sample Input: `string (foo=42)`\n",
    "- Sample Output: `<class, \"string\">, <'('>, <ID, \"foo\">, <Operator, \"=\">, <\"Int\", \"42>, <')'>`\n",
    "- Remark\n",
    "\t- **Left-to-Right** scan => **lookahead** required.\n",
    "\n",
    "#### Regular Languages\n",
    "\n",
    "Regular Expression:\n",
    "\n",
    "- Concept: Regular expressions (syntax) specify regular languages (set of strings).\n",
    "- 2 base cases\n",
    "  - Single Character: $'c' = \\{ \"c\" \\}$\n",
    "  - Empty String: $\\epsilon = \\{ \"\" \\}$\n",
    "- 3 compound expressions\n",
    "  - Union: $A + B = \\{a\\ |\\ a \\in A\\} \\cup \\{ b\\ |\\ b \\in B \\}$\n",
    "  - Concatenation: $AB = \\{ab\\ |\\ a \\in A \\wedge b \\in B \\}$\n",
    "  - Iteration: $\n",
    "A^* = \\bigcup_{i \\geq 0} A^i,\n",
    "\\begin{cases}\n",
    "A^i = A...A \\\\\n",
    "A^0 = \\epsilon\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "**Def.** The **regular expression** over $\\Sigma$ are the smallest set of expressions including:\n",
    "$$\n",
    "\\begin{align}\n",
    "  R &= \\epsilon \\\\\n",
    "    &|\\ 'c', c\\in\\Sigma\\\\\n",
    "    &|\\ R+R\\\\\n",
    "    &|\\ RR\\\\\n",
    "    &|\\ R^*\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Formal Languages\n",
    "\n",
    "**Def.** Let $\\Sigma$ be a set of characters (an alphabet).\n",
    "A **language** over $\\Sigma$ is a set of strings of characters drawn from $\\Sigma$.\n",
    "Meaning function $L$ maps **regular expressions** to **set of strings**.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L(\\epsilon) &= \\{ \"\" \\} \\\\\n",
    "L('c') &= \\{ \"c\" \\} \\\\\n",
    "L(A+B) &= L(A) \\cup L(B) \\\\\n",
    "L(AB) &= \\{ab\\ |\\ a \\in L(A) \\wedge b \\in L(B)\\} \\\\\n",
    "L(A^*) &= \\bigcup_{i \\geq 0} L(A)^i \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Q**:Why use a meaning function?\n",
    "\n",
    "- Make clear what is syntax, what is semantics.\n",
    "- Allow us to consider notation as a seperate issue.\n",
    "- Because exp and meanings are not 1-1.\n",
    "  - Meaning is many to one.\n",
    "\n",
    "### 04 Lexical Specifications\n",
    "\n",
    "**Lexemes**\n",
    "\n",
    "- **Keyword**: \"if\" / \"else\" / \"then\" / ...\n",
    "  - $ 'if' + 'else' + 'then' + ...$\n",
    "- **Integer**: a non-empty string of digits\n",
    "  - $digits: '0' + '1' + '2' + ...$\n",
    "  - $(digit)(digit)^* = digit^+$\n",
    "- **Identifier**: strings of letters or digits, starting with a letter\n",
    "  - $letter = 'a' + 'b' + 'c' + ... = [a-zA-Z]$\n",
    "  - $(letter)(digit+letter)^*$\n",
    "- **Whitespace**: a non-empty sequence of blanks, newlines, and tabs\n",
    "  - $('\\;' + '\\setminus n' + '\\setminus t')^+$\n",
    "\n",
    "**More regular expressions**\n",
    "\n",
    "- At least one: $A^+ = AA^*$\n",
    "- Union: $A|B = A+B$\n",
    "- Option: $A? = A+\\epsilon$\n",
    "- Range: $'a'+'b'+\\dots+'z' = [a-z]$\n",
    "- Excluded Range: $\\widehat{[a-z]} = [\\wedge a-z]$\n",
    "\n",
    "**How do we check $program \\in L(R)$**?\n",
    "\n",
    "1. Write a regular expression for the lexemes of each token class\n",
    "\t- Number $= digit^+$\n",
    "\t- Keyword $= 'if'+'else'+\\dots$\n",
    "\t- Identifiew $= letter(letter+digit)^*$\n",
    "\t- OpenPar $='('$\n",
    "\t- ...\n",
    "2. Construct $R$ to match all lexemes.\n",
    "\t- $R = Number + Keyword + Number + ... = R_1 + R_2 + ...$\n",
    "3. Let input be $x_1...x_n$. Find the longest length $i$ such that $x_1...x_i \\in L(R)$.\n",
    "4. Remove $x_1...x_i$. Go to step 3.\n",
    "5. If $x_1...x_i \\in L(R_a) \\cap L(R_b)$, apply $R_{\\min(a,b)}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Week 03: Parsing & Top-Down Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Week 04: Bottom-Up Parsing I & II\n",
    "\n",
    "### Predictive Parser: LL(1)\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "- Concept\n",
    "  - Look at the next ? tokens.\n",
    "  - No backtracking.\n",
    "  - Accept LL(K) grammars. (Left-to-Right, Leftmost derivation, k tokens)\n",
    "  - At each step, only 1 choice.\n",
    "  - To avoid ambiguousness, need to **left-factor** the grammar.\n",
    "- Parsing Table: Leftmode Non-terminal x Next Input Token\n",
    "  - Use stack to record frontier of parse tree\n",
    "- Differnce from Recursive Descent\n",
    "  - For the leftmost non-terminal **S**\n",
    "  - Look at the next input token **a**\n",
    "  - Choose the production shown at **[S,a]**\n",
    "- Reject on reaching error state\n",
    "- Accept on (end of input && empty stack)\n",
    "\n",
    "#### First Set\n",
    "\n",
    "**Def**. (First Set)\n",
    "\n",
    "$$First(X)=\\{t\\ |\\ X\\rightarrow^*t\\alpha\\}\\cup\\{\\epsilon\\ |\\ X\\rightarrow^*\\epsilon\\}$$\n",
    "\n",
    "**Algo**\n",
    "\n",
    "1. $First(X)=\\{t\\}, if\\ t\\ is\\ a\\ terminal.$\n",
    "2. $\\epsilon \\in First(X), if\n",
    "\\begin{cases}\n",
    "X\\rightarrow \\epsilon \\\\\n",
    "X\\rightarrow A_1A_2\\dots A_n, and\\ \\epsilon \\in First(A_i), \\forall 1\\leq i\\leq n\n",
    "\\end{cases}$\n",
    "3. $First(\\alpha) \\subseteq First(X), if\\ X\\rightarrow A_1A_2\\dots A_n\\alpha, and\\ \\epsilon \\in First(A_i), \\forall 1\\leq i\\leq n$\n",
    "\n",
    "#### Follow Set\n",
    "\n",
    "**Def**. (Follow Set)\n",
    "\n",
    "$$Follow(X)=\\{t\\ |\\ S\\rightarrow^*\\beta Xt\\delta\\}$$\n",
    "\n",
    "**Algo**\n",
    "\n",
    "1. $\\$ \\in Follow(S)$\n",
    "2. $First(\\beta)-\\{\\epsilon\\}\\subseteq Follow(X), for\\ each\\ A\\rightarrow\\alpha X\\beta$\n",
    "3. $Follow(A) \\subseteq Follow(X), for\\ each A\\rightarrow\\alpha X\\beta\\ where\\ \\epsilon\\in First(\\beta)$\n",
    "\n",
    "#### How to Construct LL(1) Parsing Tables\n",
    "\n",
    "- Construct a parsing table **T** for CFG **G**\n",
    "- For each production $A \\rightarrow \\alpha$ in G do:\n",
    "  - For each terminal $t \\in First(\\alpha)$, $T[A, t] = \\alpha$\n",
    "  - If $\\epsilon \\in First(\\alpha),$, for each $t \\in Follow(A)$, $T[A,t] = \\alpha$\n",
    "  - If $\\epsilon \\in First(\\alpha)$ and $ \\$ \\in Follow(A)$, $T[A,\\$] = \\alpha$\n",
    "- If any entry is multiply defined, then G is not LL(1).\n",
    "\n",
    "### Bottom-Up Parsing \n",
    "\n",
    "#### Shift-Reduce Parsing\n",
    "\n",
    "- Concept\n",
    "  - Don't need **left-factored** grammars.\n",
    "  - Reduce the string to the start symbol. (Inverting production)\n",
    "  - A bottom-up parser traces a rightmost derivation in reverse. $$\n",
    "\\begin{align}\n",
    "& int*int + int \\\\\n",
    "& \\textbf{int*T} + int \\\\\n",
    "& \\textbf{T} + int \\\\\n",
    "& T + \\textbf{T} \\\\\n",
    "& T + \\textbf{E} \\\\\n",
    "& \\textbf{E}\n",
    "\\end{align}\n",
    "$$\n",
    "  - Thm. \n",
    "    - In some step, let string as $\\alpha \\beta \\gamma$.\n",
    "    - Assume the next reduction is by $X \\rightarrow \\beta$. ($\\alpha \\beta \\gamma \\rightarrow \\alpha X \\gamma$)\n",
    "    - Then $\\gamma$ is a string which contains only terminals.\n",
    "  - Split the string as $L_{Str} | R_{Str}$.\n",
    "  - $L_{Str}$ contains non-terminals and terminals. $R_{Str}$ contains only terminals.\n",
    "- Actions\n",
    "  - **Shift**: Move | one place to the right. Shift a terminal to the left string.\n",
    "  - **Reduce**: Apply an inverse production at the right of $L_{str}$. $$\n",
    "for\\ A \\rightarrow xy, Cbxy|ijk \\Rightarrow CbA|ijk $$\n",
    "- Implementation\n",
    "  - Use a stack to maintain $L_{Str}$.\n",
    "- If is's legal to shift or reduce, there is a **shift-reduce** conflict.\n",
    "- If is's legal to reduce by 2 productions, there is a **reduce-reduce** conflict.\n",
    "\n",
    "#### Term. (Handle)\n",
    "\n",
    "- Scenario\n",
    "  - Grammar: $E \\rightarrow T+E|E$ & $T \\rightarrow int*T|int|(E)$\n",
    "  - At the steop $int|*int+int$\n",
    "  - If we reduce by ($T \\rightarrow int$) given ($T | *int+int$), it will fail.\n",
    "- Target: Want to reduce only if the result can still be reduced to the start symbol.\n",
    "- Assume a rightmost derivation $$S \\rightarrow^* \\alpha X \\omega \\rightarrow \\alpha\\beta\\omega$$\n",
    "  - Then $\\beta$ is a **handle** of $\\alpha \\beta \\omega$.\n",
    "- Thm.\n",
    "  - In shift-reduce parsing, handles appear only **at the top of the stack**, never inside.\n",
    "- Bottom-up parsing algorithms are based on recognizing handles\n",
    "\n",
    "#### Recognizing Handles\n",
    "\n",
    "- **Viable Prefix**: $\\alpha_1\\dots\\alpha_n$ is a **viable prefix** if there is an $\\omega$ s.t. $\\alpha_1\\dots\\alpha_n | \\omega$ is a state of a shift-reduce parser.\n",
    "- For any grammar, the set of viable prefixes is a **regular language**.\n",
    "- **Item**: An **item** is a production with '.' somewhere on the rhs.\n",
    "  - Example. The items for $T \\rightarrow (E)$ are\n",
    "    - $T \\rightarrow .(E)$\n",
    "    - $T \\rightarrow (.E)$\n",
    "    - $T \\rightarrow (E.)$\n",
    "    - $T \\rightarrow (E).$\n",
    "  - Example. The items for ($X \\rightarrow \\epsilon$) are $X \\rightarrow .$\n",
    "  - Items are often called **LR(0) items**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Week 05: Semantic Analysis and Type Checking\n",
    "\n",
    "## Week 06: Cool Type Checking & Runtime Organization\n",
    "\n",
    "## Week 07: Code Generation & Operational Semantics\n",
    "\n",
    "## Week 08: Local Optimization & Global Optimization\n",
    "\n",
    "## Week 09: Register Allocation & Garbage Collection\n",
    "\n",
    "## Week 10: Java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
