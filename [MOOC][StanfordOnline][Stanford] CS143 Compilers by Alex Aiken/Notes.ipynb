{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Notes for Stanford CS143 Compilers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Week 01: Introduction & the Cool Programming Language\n",
    "\n",
    "**How to Run the Program**\n",
    "\n",
    "- Compiler (Offline)\n",
    "  - $Program \\rightarrow Compiler \\rightarrow Execute$\n",
    "  - $Execute + Data \\rightarrow Output$\n",
    "- Interpreters (Online)\n",
    "  - $Program + Data \\rightarrow Interpreter \\rightarrow Output$\n",
    "\n",
    "**Compiler Concept**\n",
    "\n",
    "- (Syntactic) **Lexical Analysis**\n",
    "  - Concept: Divide program text into words or tokens.\n",
    "  - Input: text\n",
    "  - Output: words or tokens\n",
    "  - Sample Input: `if x == y then z = 1; else z = 2;`\n",
    "  - Sample Output: `#IF #ID(x) #EQAUL #ID(y) #THEN ...`\n",
    "- (Syntactic) **Parsing**\n",
    "  - Concept: Diagramming Sentences.\n",
    "  - Input: Tokens\n",
    "  - Output: Abstruct Semantic Tree\n",
    "  - Sample Input: #INT(5) #PLUS #INT(3) #MULTIPLY #INT(5)\n",
    "  - Sample Output: `(#PLUS (#INT(5))  (#MULTIPLY (#INT(3))  (#INT(5))))`\n",
    "- (Types scope) **Semantic Analysis**\n",
    "  - Concept: Catch inconsistencies.\n",
    "  - Sample Input: `{ int Jack=3; { int Jack=4; cout << Jack; } }`\n",
    "  - Question: What is the value?\n",
    "- **Optimization**\n",
    "  - Concept: Run faster/Use less memory/Use low power/network.\n",
    "- (Translation) **Code Generation**\n",
    "  - Concept: Produce assembly code.\n",
    "\n",
    "**Related Questions**\n",
    "\n",
    "- Why are there so many programming languages?\n",
    "  - Application domains have distinct/conflicting needs.\n",
    "- Why are there new programming languages?\n",
    "  - Programming training is the dominant cost for a programming language.\n",
    "  - Wild-used languages are **slow to change**.\n",
    "  - Easy to start a new language: when **productivity** > **training cost**\n",
    "  - Languages adopted to fill a void. (**Void** means new techniques.)\n",
    "- What is a good programming languages?\n",
    "  - There is **no** universally accepted metric for language design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Week 02: Lexical Analysis & Finite Automata\n",
    "\n",
    "### 03 Lexical Analysis\n",
    "\n",
    "**Token Class (or Class)**\n",
    "\n",
    "Classify **program substrings** according to **role** (token class), **class** corresponding to **sets of strings**:\n",
    "\n",
    "- **Identifier** : string of letters or digits, starting with a letter\n",
    "- **Integer**: a non-empty string of digits\n",
    "- **Keyword**: else, if, begin, ...\n",
    "- **Whitespace**: a non-empty sequence of blanks, newlines, tabs\n",
    "\n",
    "**Goal of Lexical Analysis**\n",
    "\n",
    "- Definition\n",
    "\t- **lexeme**: A lexeme is a sequence of characters that matches the pattern for a token.\n",
    "\t- **token**: A token is a pair consisting of the token name and the value.\n",
    "- Concept\n",
    "\t- Parttition the input string into lexemes.\n",
    "\t- Identity the token of each lexeme.\n",
    "\t- Communicate tokens to the parser.\n",
    "- Input: Program Substrings\n",
    "- Output: Tokens\n",
    "- Sample Input: `string (foo=42)`\n",
    "- Sample Output: `<class, \"string\">, <'('>, <ID, \"foo\">, <Operator, \"=\">, <\"Int\", \"42>, <')'>`\n",
    "- Remark\n",
    "\t- **Left-to-Right** scan => **lookahead** required.\n",
    "\n",
    "#### Regular Languages\n",
    "\n",
    "Regular Expression:\n",
    "\n",
    "- Concept: Regular expressions (syntax) specify regular languages (set of strings).\n",
    "- 2 base cases\n",
    "  - Single Character: $'c' = \\{ \"c\" \\}$\n",
    "  - Empty String: $\\epsilon = \\{ \"\" \\}$\n",
    "- 3 compound expressions\n",
    "  - Union: $A + B = \\{a\\ |\\ a \\in A\\} \\cup \\{ b\\ |\\ b \\in B \\}$\n",
    "  - Concatenation: $AB = \\{ab\\ |\\ a \\in A \\wedge b \\in B \\}$\n",
    "  - Iteration: $\n",
    "A^* = \\bigcup_{i \\geq 0} A^i,\n",
    "\\begin{cases}\n",
    "A^i = A...A \\\\\n",
    "A^0 = \\epsilon\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "**Def.** The **regular expression** over $\\Sigma$ are the smallest set of expressions including:\n",
    "$$\n",
    "\\begin{align}\n",
    "  R &= \\epsilon \\\\\n",
    "    &|\\ 'c', c\\in\\Sigma\\\\\n",
    "    &|\\ R+R\\\\\n",
    "    &|\\ RR\\\\\n",
    "    &|\\ R^*\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Formal Languages\n",
    "\n",
    "**Def.** Let $\\Sigma$ be a set of characters (an alphabet).\n",
    "A **language** over $\\Sigma$ is a set of strings of characters drawn from $\\Sigma$.\n",
    "Meaning function $L$ maps **regular expressions** to **set of strings**.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L(\\epsilon) &= \\{ \"\" \\} \\\\\n",
    "L('c') &= \\{ \"c\" \\} \\\\\n",
    "L(A+B) &= L(A) \\cup L(B) \\\\\n",
    "L(AB) &= \\{ab\\ |\\ a \\in L(A) \\wedge b \\in L(B)\\} \\\\\n",
    "L(A^*) &= \\bigcup_{i \\geq 0} L(A)^i \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Q**:Why use a meaning function?\n",
    "\n",
    "- Make clear what is syntax, what is semantics.\n",
    "- Allow us to consider notation as a seperate issue.\n",
    "- Because exp and meanings are not 1-1.\n",
    "  - Meaning is many to one.\n",
    "\n",
    "### 04 Lexical Specifications\n",
    "\n",
    "**Lexemes**\n",
    "\n",
    "- **Keyword**: \"if\" / \"else\" / \"then\" / ...\n",
    "  - $ 'if' + 'else' + 'then' + ...$\n",
    "- **Integer**: a non-empty string of digits\n",
    "  - $digits: '0' + '1' + '2' + ...$\n",
    "  - $(digit)(digit)^* = digit^+$\n",
    "- **Identifier**: strings of letters or digits, starting with a letter\n",
    "  - $letter = 'a' + 'b' + 'c' + ... = [a-zA-Z]$\n",
    "  - $(letter)(digit+letter)^*$\n",
    "- **Whitespace**: a non-empty sequence of blanks, newlines, and tabs\n",
    "  - $('\\;' + '\\setminus n' + '\\setminus t')^+$\n",
    "\n",
    "**More regular expressions**\n",
    "\n",
    "- At least one: $A^+ = AA^*$\n",
    "- Union: $A|B = A+B$\n",
    "- Option: $A? = A+\\epsilon$\n",
    "- Range: $'a'+'b'+\\dots+'z' = [a-z]$\n",
    "- Excluded Range: $\\widehat{[a-z]} = [\\wedge a-z]$\n",
    "\n",
    "**How do we check $program \\in L(R)$**?\n",
    "\n",
    "1. Write a regular expression for the lexemes of each token class\n",
    "\t- Number $= digit^+$\n",
    "\t- Keyword $= 'if'+'else'+\\dots$\n",
    "\t- Identifiew $= letter(letter+digit)^*$\n",
    "\t- OpenPar $='('$\n",
    "\t- ...\n",
    "2. Construct $R$ to match all lexemes.\n",
    "\t- $R = Number + Keyword + Number + ... = R_1 + R_2 + ...$\n",
    "3. Let input be $x_1...x_n$. Find the longest length $i$ such that $x_1...x_i \\in L(R)$.\n",
    "4. Remove $x_1...x_i$. Go to step 3.\n",
    "5. If $x_1...x_i \\in L(R_a) \\cap L(R_b)$, apply $R_{\\min(a,b)}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Week 03: Parsing & Top-Down Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Week 04: Bottom-Up Parsing I & II\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Week 05: Semantic Analysis and Type Checking\n",
    "\n",
    "## Week 06: Cool Type Checking & Runtime Organization\n",
    "\n",
    "## Week 07: Code Generation & Operational Semantics\n",
    "\n",
    "## Week 08: Local Optimization & Global Optimization\n",
    "\n",
    "## Week 09: Register Allocation & Garbage Collection\n",
    "\n",
    "## Week 10: Java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
